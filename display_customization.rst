Customize Display Options
==========================

1.How to visualize the questions with or without a score ?
----------------------------------------------------------

In the analysis grid, you can choose to display all the questions, those with a score, or those without a score.

(vidéo)

2.How to change the display mode ?
----------------------------------

You can choose to display either a dark mode or a light mode.

(vidéo)





4. Access and reuse an existing dashboard
-----------------------------------------

If you want to use a dashboard that was created by another user in the system, follow these steps:

1. Go to the section called **"All Dashboards"**
2. Locate the dashboard you want to use (e.g., alert monitoring, performance tracking, etc.)
3. Click on the **eye icon** to open it

Once inside the dashboard, you will find several options in the top-right corner:

.. raw:: html

   <div style="text-align: center;">
     <img src="_static/Dashbord.png" width="500" alt="Dashboard list">
   </div>

You can choose between the following actions:

- **Add to my favorites**  
  Adds the dashboard to your side menu. Any future changes made by the original creator will be reflected on your side.

.. raw:: html

   <div style="text-align: center;">
     <img src="_static/ADD_TO_MY_FAVORITES.png" width="300" alt="Add to my favorites">
   </div>

- **Duplicate**  
  Creates a fully independent copy of the dashboard. You can then customize it freely (add widgets, edit filters, etc.) without affecting the original.

- **Set as Home Page**  
  If you want this dashboard to appear when you log in, click the gear icon and enable “Home Page” from the settings.

.. raw:: html

   <div style="text-align: center;">
     <img src="_static/Dashbord_Settings.png" width="400" alt="Dashboard settings">
   </div>

















5. How to manage and respond to comments ?
-------------------------------------------

If you disagree with the AI's automatic evaluation, you can request a review through the **counter evaluation** workflow.

### Steps to follow:

1. Open the evaluation view of the call
2. In the section **Conter evaluation by**, enter your **first name** to identify yourself

.. raw:: html

   <div style="text-align: center;">
     <img src="_static/Conter_evaluation_by.png" width="700" alt="Conter evaluation by field">
   </div>

3. Scroll down and enter your explanation or justification in the **Comment** section

.. raw:: html

   <div style="text-align: center;">
     <img src="_static/Comment.png" width="800" alt="Comment section input">
   </div>

4. Set the **Debug Status** to `Open` to notify the quality team

.. raw:: html

   <div style="text-align: center;">
     <img src="_static/Debug_Status.png" width="400" alt="Debug status dropdown">
   </div>

---

### Workflow explanation:

- **Open** = a new comment is submitted and waiting for review  
- **Pending** = a reviewer is working on your case before giving an answer  
- **Replied** = a reply has been written in the `ANSWER` field  
- **Closed** = the problem is resolved and the process is complete

This system ensures that every feedback is reviewed and responded to by the quality team in a structured and traceable way.



4. Understanding the IA vs Human comparison dashboard
This page allows you to explore the differences between evaluations made by the AI and those made by human reviewers.

1. Score Table
This table displays, for each counter-evaluator and each call, the human score, the AI score, and the difference between the two.
If a counter-evaluator (e.g. Hayat) does not appear, it means no human score has been recorded for the selected period or filters.


.. raw:: html

<div style="text-align: center;"> 
       <img src="_static/Score Table.png" width="800" alt="Score table by counter-evaluator">
</div>

2. Evolution of the average gap between IA and human scores
This graph shows the trend of the average difference between the human and AI scores over time (day, week, or month depending on filters).

.. raw:: html

<div style="text-align: center;"> 
<img src="_static/Evolution of the average gap between IA and human scores.png" width="800" alt="Line chart showing average gap over time"> 
</div>

3. Question-wise Accuracy Table
This visual presents, for each question, the percentage of correct and incorrect responses by the AI (based on human validation) per counter-evaluator.

.. raw:: html

<div style="text-align: center;"> 
<img src="_static/Question-wise Accuracy Table.png" width="800" alt="Accuracy per question and reviewer"> 
</div>

4. Call-by-Call Details
This detailed table shows the call ID, agent name, counter-evaluator, the evaluated question, the human answer, the AI answer, and whether the AI's response was correct or not.

.. raw:: html





Understanding the IA vs Human Comparison Dashboard

This page allows you to explore the differences between evaluations made by the AI and those made by human reviewers. It is divided into four key visualizations to support your analysis.

5.1. Score Table (by counter-evaluator)
This table displays, for each counter-evaluator and each call:

the human score

the AI score

the gap (difference) between the two

If a counter-evaluator (e.g. Hayat) does not appear, it means no human score has been recorded for the selected filters.

.. raw:: html

<div style="text-align: center;"> <img src="_static/Score Table.png" width="800" alt="Score table by counter-evaluator"> </div>
5.2. Evolution of the Average Gap
This graph shows the trend of the average difference between human and AI scores over time.
You can choose to display this evolution by day, week, or month, using the calendar filters in the dashboard.

.. raw:: html

<div style="text-align: center;"> <img src="_static/Evolution of the average gap between IA and human scores.png" width="800" alt="Average gap over time"> </div>
5.3. Question-wise Accuracy Table
This visualization shows, for each question and counter-evaluator:

the percentage of correct answers by the AI

the percentage of incorrect answers based on the human review

It helps identify which types of questions may need further adjustments.

.. raw:: html

<div style="text-align: center;"> <img src="_static/Question-wise Accuracy Table.png" width="800" alt="Accuracy per question and reviewer"> </div>
5.4. Call-by-Call Details
This table allows you to review individual calls. For each line, you can see:

the call ID, agent, and counter-evaluator

the question being evaluated

the human value and AI value

whether the AI’s answer was correct or not

.. raw:: html

<div style="text-align: center;"> <img src="_static/Call-by-Call Details.png" width="800" alt="Call-by-call analysis table"> </div>


